{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8969368",
   "metadata": {},
   "source": [
    "### –û–ø—Ä–∞—Ü—é–≤–∞–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96d4a7",
   "metadata": {},
   "source": [
    "- —á–∏—Ç–∞—î–º–æ —Ñ–∞–π–ª–∏ –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º –∫–æ–¥—É–≤–∞–Ω–Ω—è–º —Ç–∞ —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞–º–∏\n",
    "- –ø—Ä–∏–≤–æ–¥–∏–º–æ url –¥–æ –Ω–∏–∂–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É\n",
    "- —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –∞–∫–æ—Ä–¥—ñ–≤ —É –≤–∏–≥–ª—è–¥—ñ \"main accords: ...\"\n",
    "- –≤–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ mainaccord-–∫–æ–ª–æ–Ω–∫–∏, —è–∫—â–æ —î\n",
    "- –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –Ω–æ–≤–∏–π —Ñ–∞–π–ª fra_main.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "57346819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–∑–±–µ—Ä–µ–∂–µ–Ω–æ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "OPENROUTER_KEY = os.getenv(\"OPENROUTER_KEY\")\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "\n",
    "fra_perfumes = pd.read_csv(\"data/fra_perfumes.csv\", encoding=\"utf-8\")\n",
    "fra_cleaned = pd.read_csv(\"data/fra_cleaned.csv\", sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "fra_perfumes[\"url\"] = fra_perfumes[\"url\"].str.lower()\n",
    "fra_cleaned[\"url\"] = fra_cleaned[\"url\"].str.lower()\n",
    "\n",
    "def format_accords(accord_str):\n",
    "    try:\n",
    "        accords = ast.literal_eval(accord_str)\n",
    "        if isinstance(accords, list):\n",
    "            return \"main accords: \" + \", \".join(accords)\n",
    "    except:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "fra_perfumes[\"Main Accords\"] = fra_perfumes[\"Main Accords\"].apply(format_accords)\n",
    "merged = fra_cleaned.merge(\n",
    "    fra_perfumes[[\"url\", \"Main Accords\"]],\n",
    "    on=\"url\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "columns_to_drop = [\"mainaccord1\", \"mainaccord2\", \"mainaccord3\", \"mainaccord4\", \"mainaccord5\"]\n",
    "merged = merged.drop(columns=[c for c in columns_to_drop if c in merged.columns])\n",
    "\n",
    "\n",
    "merged.to_csv(\"data/fra_main.csv\", sep=\";\", index=False, encoding=\"utf-8\")\n",
    "print(\"–∑–±–µ—Ä–µ–∂–µ–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64082783",
   "metadata": {},
   "source": [
    "- —É fra_main.csv –≤—Å—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑ º—î–¥–Ω–∞—Ç–∏ —ñ –æ—Ç—Ä–∏–º—É—î–º–æ Description\n",
    "- —Å—Ç–≤–æ—Ä—é—î–º–æ –±–∞–∑–æ–≤–µ —Ä–µ—á–µ–Ω–Ω—è –æ–ø–∏—Å—É:\n",
    "    1. –ù–∞–∑–≤–∞ + –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è: \"The {Perfume} is designed for {Gender}.\"\n",
    "    2. –ë—Ä–µ–Ω–¥, –∫—Ä–∞—ó–Ω–∞, —Ä—ñ–∫: \"Brand {Brand}, {Country}, created in {Year}.\"\n",
    "    3. –¢–æ–ø –Ω–æ—Ç–∏: \"Top notes are {Top}.\"\n",
    "    4. –°–µ—Ä–µ–¥–Ω—ñ –Ω–æ—Ç–∏: \"Middle notes are {Middle}.\"\n",
    "    5. –ë–∞–∑–æ–≤—ñ –Ω–æ—Ç–∏: \"Base notes are {Base}.\"\n",
    "    6. –ì–æ–ª–æ–≤–Ω—ñ –∞–∫–æ—Ä–¥–∏: \"Main accords include {Main Accords}.\"\n",
    "- –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª —è–∫ fra_working.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "85bf82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–∑–±–µ—Ä–µ–∂–µ–Ω–æ\n"
     ]
    }
   ],
   "source": [
    "fra_main = pd.read_csv(\"data/fra_main.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "def make_description_en(row):\n",
    "    parts = []\n",
    "    \n",
    "    if pd.notna(row[\"Perfume\"]):\n",
    "        text = f\"The {row['Perfume']}\"\n",
    "        if pd.notna(row[\"Gender\"]):\n",
    "            text += f\" is designed for {row['Gender']}\"\n",
    "        parts.append(text + \".\")\n",
    "    \n",
    "    brand_country_year = []\n",
    "    if pd.notna(row[\"Brand\"]):\n",
    "        brand_country_year.append(f\"Brand {row['Brand']}\")\n",
    "    if pd.notna(row[\"Country\"]):\n",
    "        brand_country_year.append(row[\"Country\"])\n",
    "    if pd.notna(row[\"Year\"]):\n",
    "        brand_country_year.append(f\"created in {int(row['Year'])}\")\n",
    "    if brand_country_year:\n",
    "        parts.append(\", \".join(brand_country_year) + \".\")\n",
    "    \n",
    "    if pd.notna(row[\"Top\"]):\n",
    "        parts.append(f\"Top notes are {row['Top']}.\")\n",
    "    \n",
    "    if pd.notna(row[\"Middle\"]):\n",
    "        parts.append(f\"Middle notes are {row['Middle']}.\")\n",
    "    \n",
    "    if pd.notna(row[\"Base\"]):\n",
    "        parts.append(f\"Base notes are {row['Base']}.\")\n",
    "    \n",
    "    if pd.notna(row[\"Main Accords\"]):\n",
    "        accords = row[\"Main Accords\"].replace(\"main accords:\", \"\").strip()\n",
    "        parts.append(f\"Main accords include {accords}.\")\n",
    "    \n",
    "    return \" \".join(parts)\n",
    "\n",
    "fra_main[\"Description\"] = fra_main.apply(make_description_en, axis=1)\n",
    "fra_main.to_csv(\"data/fra_working.csv\", sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"–∑–±–µ—Ä–µ–∂–µ–Ω–æ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa3b86",
   "metadata": {},
   "source": [
    "–∫—ñ–Ω—Ü–µ–≤–∏–π —Ñ–∞–π–ª –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –¥–∞–ª—ñ, –∑–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ url —Ç–∞ description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3b992c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–∑–±–µ—Ä–µ–∂–µ–Ω–æ\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/fra_working.csv\", sep=\";\")\n",
    "df_clean = df[['url', 'Description']]\n",
    "df_clean.to_csv(\"data/fra_final.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(\"–∑–±–µ—Ä–µ–∂–µ–Ω–æ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8eae23",
   "metadata": {},
   "source": [
    "### –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —É –≤–µ–∫—Ç–æ—Ä–Ω—É –¥–∞—Ç–∞–±–∞–∑—É\n",
    "- 1 –≤–µ–∫—Ç–æ—Ä –Ω–∞ discription\n",
    "- –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ —á–µ—Ä–µ–∑ –µ–º–±–µ–¥–∏–Ω–≥–æ–≤—É –º–æ–¥–µ–ª—å sentence-transformers/all-MiniLM-L6-v2 (–¥–∞–ª—ñ –±—É–¥–µ –ø–æ–∫—Ä–∞—â–µ–Ω–æ –∑ BAAI)\n",
    "- –æ—Ç—Ä–∏–º—É—î–º–æ [–í–µ–∫—Ç–æ—Ä–∏ –∞—Ä–æ–º–∞—Ç—ñ–≤]\n",
    "- –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ —É –≤–µ–∫—Ç–æ—Ä–Ω—É –±–∞–∑—É –¥–∞–Ω–∏—Ö weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "02c64107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(95547) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: weaviate-client in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.17.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/veronikabagatyr-zaharcenko/Library/Python/3.11/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (0.27.0)\n",
      "Requirement already satisfied: validators<1.0.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (0.35.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (1.6.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (2.12.2)\n",
      "Requirement already satisfied: grpcio<1.80.0,>=1.59.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (1.75.1)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (5.27.2)\n",
      "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (2.1.0)\n",
      "Requirement already satisfied: cryptography in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (46.0.3)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.5)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.7)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d668dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4016a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_faster = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4e08efb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  \\\n",
      "0  https://www.fragrantica.com/perfume/xerjoff/ac...   \n",
      "1  https://www.fragrantica.com/perfume/jean-paul-...   \n",
      "2  https://www.fragrantica.com/perfume/jean-paul-...   \n",
      "3  https://www.fragrantica.com/perfume/bruno-bana...   \n",
      "4  https://www.fragrantica.com/perfume/jean-paul-...   \n",
      "\n",
      "                                         Description  \n",
      "0  The accento-overdose-pride-edition is designed...  \n",
      "1  The classique-pride-2024 is designed for women...  \n",
      "2  The classique-pride-2023 is designed for unise...  \n",
      "3  The pride-edition-man is designed for men. Bra...  \n",
      "4  The le-male-pride-collector is designed for me...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/fra_final.csv\", delimiter=\";\")\n",
    "print(df.head())\n",
    "\n",
    "url_embeddings = model_faster.encode(df[\"url\"].tolist(), convert_to_numpy=True)\n",
    "desc_embeddings = model_faster.encode(df[\"Description\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "df[\"url_embedding\"] = url_embeddings.tolist()\n",
    "df[\"desc_embedding\"] = desc_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "481afd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Description</th>\n",
       "      <th>url_embedding</th>\n",
       "      <th>desc_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.fragrantica.com/perfume/xerjoff/ac...</td>\n",
       "      <td>The accento-overdose-pride-edition is designed...</td>\n",
       "      <td>[-0.04432978108525276, -0.009280748665332794, ...</td>\n",
       "      <td>[-0.03480173647403717, -0.052203211933374405, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.fragrantica.com/perfume/jean-paul-...</td>\n",
       "      <td>The classique-pride-2024 is designed for women...</td>\n",
       "      <td>[-0.07233968377113342, 0.03223196417093277, 0....</td>\n",
       "      <td>[-0.03264125809073448, -0.013616586104035378, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.fragrantica.com/perfume/jean-paul-...</td>\n",
       "      <td>The classique-pride-2023 is designed for unise...</td>\n",
       "      <td>[-0.07958675920963287, 0.03121933341026306, 0....</td>\n",
       "      <td>[-0.06086841970682144, -0.0029787395615130663,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.fragrantica.com/perfume/bruno-bana...</td>\n",
       "      <td>The pride-edition-man is designed for men. Bra...</td>\n",
       "      <td>[-0.040581244975328445, 0.023872805759310722, ...</td>\n",
       "      <td>[-0.013094151392579079, 0.0003859872813336551,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.fragrantica.com/perfume/jean-paul-...</td>\n",
       "      <td>The le-male-pride-collector is designed for me...</td>\n",
       "      <td>[-0.09335911273956299, 0.04805570840835571, 0....</td>\n",
       "      <td>[-0.05961913615465164, -0.02085302770137787, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.fragrantica.com/perfume/xerjoff/ac...   \n",
       "1  https://www.fragrantica.com/perfume/jean-paul-...   \n",
       "2  https://www.fragrantica.com/perfume/jean-paul-...   \n",
       "3  https://www.fragrantica.com/perfume/bruno-bana...   \n",
       "4  https://www.fragrantica.com/perfume/jean-paul-...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  The accento-overdose-pride-edition is designed...   \n",
       "1  The classique-pride-2024 is designed for women...   \n",
       "2  The classique-pride-2023 is designed for unise...   \n",
       "3  The pride-edition-man is designed for men. Bra...   \n",
       "4  The le-male-pride-collector is designed for me...   \n",
       "\n",
       "                                       url_embedding  \\\n",
       "0  [-0.04432978108525276, -0.009280748665332794, ...   \n",
       "1  [-0.07233968377113342, 0.03223196417093277, 0....   \n",
       "2  [-0.07958675920963287, 0.03121933341026306, 0....   \n",
       "3  [-0.040581244975328445, 0.023872805759310722, ...   \n",
       "4  [-0.09335911273956299, 0.04805570840835571, 0....   \n",
       "\n",
       "                                      desc_embedding  \n",
       "0  [-0.03480173647403717, -0.052203211933374405, ...  \n",
       "1  [-0.03264125809073448, -0.013616586104035378, ...  \n",
       "2  [-0.06086841970682144, -0.0029787395615130663,...  \n",
       "3  [-0.013094151392579079, 0.0003859872813336551,...  \n",
       "4  [-0.05961913615465164, -0.02085302770137787, -...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd74c5f",
   "metadata": {},
   "source": [
    "### –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ —É –≤–µ–∫—Ç–æ—Ä–Ω—É –±–∞–∑—É –¥–∞–Ω–∏—Ö weaviate\n",
    "- –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ Weaviate Cloud\n",
    "- –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–µ–∫—Ü—ñ—ó (Perfume) (+ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —ñ—Å–Ω—É—î —ñ –æ—á–∏—â–µ–Ω–Ω—è, —â–æ–± –Ω–µ –±—É–ª–æ –∑–±–æ—é –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ)\n",
    "- –î–æ–¥–∞–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö —É –∫–æ–ª–µ–∫—Ü—ñ—é: –î–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞ –¥–æ–¥–∞—î–º–æ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ (url, description) —ñ –≥–æ—Ç–æ–≤–∏–π –≤–µ–∫—Ç–æ—Ä (desc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1ad12374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(96494) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: weaviate-client in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.17.0)\n",
      "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (0.27.0)\n",
      "Requirement already satisfied: validators<1.0.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (0.35.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (1.6.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (2.12.2)\n",
      "Requirement already satisfied: grpcio<1.80.0,>=1.59.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (1.75.1)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (5.27.2)\n",
      "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weaviate-client) (2.1.0)\n",
      "Requirement already satisfied: cryptography in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (46.0.3)\n",
      "Requirement already satisfied: packaging in /Users/veronikabagatyr-zaharcenko/Library/Python/3.11/lib/python/site-packages (from deprecation<3.0.0,>=2.1.0->weaviate-client) (23.2)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from grpcio<1.80.0,>=1.59.5->weaviate-client) (4.15.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.5)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.7)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.4.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e3460bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "weaviate_url = ...\n",
    "weaviate_api_key = ...\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key)\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b0b4d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–µ–∫—Ü—ñ—è Perfume —Å—Ç–≤–æ—Ä–µ–Ω–∞!\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure\n",
    "\n",
    "if client.collections.exists(\"Perfume\"):\n",
    "    client.collections.delete(\"Perfume\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Perfume\",\n",
    "    description=\"Perfume DB with one desc vector\",\n",
    "    properties=[\n",
    "        Property(name=\"url\", data_type=DataType.TEXT),\n",
    "        Property(name=\"description\", data_type=DataType.TEXT),\n",
    "    ],\n",
    "    vector_config={\n",
    "        \"name\": \"desc_embedding\",\n",
    "        \"vectorizer\": Configure.Vectorizer.none(),\n",
    "        \"vectorIndexConfig\": Configure.VectorIndex.hnsw()._to_dict()\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"–ö–æ–ª–µ–∫—Ü—ñ—è Perfume —Å—Ç–≤–æ—Ä–µ–Ω–∞!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5efa59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"Perfume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bf04c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/weaviate/warnings.py:302: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n",
      "/var/folders/4c/kdt7jcqj4vqf7lchj5_c7vyh0000gn/T/ipykernel_7484/3260888946.py:1: ResourceWarning: unclosed <ssl.SSLSocket fd=93, family=30, type=1, proto=0, laddr=('2a02:2378:108e:cdca:9447:739a:2087:3581', 50342, 0, 0), raddr=('64:ff9b::226f:f515', 443, 0, 0)>\n",
      "  with collection.batch.fixed_size(100) as batch:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∞–Ω—ñ –¥–æ–¥–∞–Ω—ñ –≤ –∫–æ–ª–µ–∫—Ü—ñ—é\n"
     ]
    }
   ],
   "source": [
    "with collection.batch.fixed_size(100) as batch:\n",
    "    for _, row in df.iterrows():\n",
    "        batch.add_object(\n",
    "            properties={\n",
    "                \"url\": row[\"url\"],\n",
    "                \"description\": row[\"Description\"],\n",
    "            },\n",
    "            vector={  \n",
    "                \"desc_embedding\": row[\"desc_embedding\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(\"–î–∞–Ω—ñ –¥–æ–¥–∞–Ω—ñ –≤ –∫–æ–ª–µ–∫—Ü—ñ—é\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bdba9588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–±'—î–∫—Ç—ñ–≤: 24104\n"
     ]
    }
   ],
   "source": [
    "print(\"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–±'—î–∫—Ç—ñ–≤:\", collection.aggregate.over_all(total_count=True).total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f01bb0",
   "metadata": {},
   "source": [
    "### –û–±—Ä–æ–±–∫–∞ –∑–∞–ø–∏—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Ç–∞ —Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca4408",
   "metadata": {},
   "source": [
    "- –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞\n",
    "- –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –Ω–∞ –≤–µ–∫—Ç–æ—Ä (embedding –∑ —Ç—ñ—î—é –∂ –º–æ–¥–µ–ª–ª—é)\n",
    "- –ü–æ—à—É–∫ –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Ç–æ–ø-5 –≤–µ–∫—Ç–æ—Ä—ñ–≤ —É –∫–æ–ª–µ–∫—Ü—ñ—ó –¥–æ \"–≤–µ–∫—Ç–æ—Ä–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞\": Weaviate —à—É–∫–∞—î —Ç–æ–ø-5 –Ω–∞–π–±—ñ–ª—å—à —Å—Ö–æ–∂–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ —É –∫–æ–ª–µ–∫—Ü—ñ—ó –∑–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º approximate nearest neighbor (ANN). –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –º–µ—Ç—Ä–∏–∫–∞ —Å—Ö–æ–∂–æ—Å—Ç—ñ cosine similarity. –°–ø–∏—Å–æ–∫ –≤–∂–µ —Ä–∞–Ω–∂–æ–≤–∞–Ω–∏–π –≤—ñ–¥ –Ω–∞–π–±—ñ–ª—å—à –¥–æ –º–µ–Ω—à —Å—Ö–æ–∂–æ–≥–æ, —Ç–æ–±—Ç–æ –ø–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç ‚Äî –Ω–∞–π–±—ñ–ª—å—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π.\n",
    "- –§—ñ–ª—å—Ç—Ä –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π, —è–∫—â–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Å—Ö–æ–∂—ñ—Å—Ç—å (certainty) –º–µ–Ω—à–∞ 0.5 –ø–æ cosine similarity, —Ç–æ —Ü–µ–π –ø–∞—Ä—Ñ—É–º —É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–µ –≤–∏–≤–æ–¥–∏—Ç—å—Å—è\n",
    "- –í–∏–≤–µ–¥–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤, URL —Ç–∞ Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "01a5a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.fragrantica.com/perfume/dame-perfumery/peach-blossom-violet-vanilla-27032.html\n",
      "Description: The peach-blossom-violet-vanilla is designed for women. Brand dame-perfumery, USA, created in 2014. Top notes are peach blossom, hyacinth, red berries, bergamot. Middle notes are parma violet, jasmine, rose. Base notes are musk, tahitian vanilla, driftwood. Main accords include floral, powdery, violet, fruity, fresh spicy, fresh, musky, green, vanilla.\n",
      "Cosine similarity: 0.699\n",
      "------------------------------------------------------------\n",
      "URL: https://www.fragrantica.com/perfume/the-body-shop/vanilla-perfume-oil-3630.html\n",
      "Description: The vanilla-perfume-oil is designed for women. Brand the-body-shop, UK. Top notes are peach, lemon, apricot, plum. Middle notes are jasmine, ylang-ylang, tuberose, lily-of-the-valley, rose, orange blossom. Base notes are vanilla, amber, sandalwood, musk. Main accords include vanilla, powdery, sweet, white floral, fruity, woody, amber.\n",
      "Cosine similarity: 0.695\n",
      "------------------------------------------------------------\n",
      "URL: https://www.fragrantica.com/perfume/the-body-shop/the-spirit-of-moonflower-perfume-oil-3629.html\n",
      "Description: The the-spirit-of-moonflower-perfume-oil is designed for women. Brand the-body-shop, UK. Top notes are melon, gardenia, coriander. Middle notes are lime (linden) blossom, cyclamen, lily-of-the-valley. Base notes are rose, jasmine. Main accords include white floral, fresh, floral, rose, yellow floral, aquatic, sweet, ozonic, green, fruity.\n",
      "Cosine similarity: 0.672\n",
      "------------------------------------------------------------\n",
      "URL: https://www.fragrantica.com/perfume/providence-perfume-co/divine-11579.html\n",
      "Description: The divine is designed for women. Brand providence-perfume-co, USA, created in 2009. Top notes are bitter orange, coriander, bergamot. Middle notes are neroli, african orange flower, jasmine, rose. Base notes are amber, ambrette (musk mallow), vanille, angelica, musk. Main accords include citrus, white floral, amber, musky, aromatic, floral, powdery, fresh, vanilla, fresh spicy.\n",
      "Cosine similarity: 0.664\n",
      "------------------------------------------------------------\n",
      "URL: https://www.fragrantica.com/perfume/floral-street/wild-vanilla-orchid-47212.html\n",
      "Description: The wild-vanilla-orchid is designed for unisex. Brand floral-street, UK, created in 2017. Top notes are vanilla flower, cassis, citruses. Middle notes are bamboo, flowers, jasmine. Base notes are vanilla bean, sandalwood, orchid, patchouli. Main accords include woody, vanilla, floral, powdery, aromatic, soft spicy, fruity, green, earthy, fresh.\n",
      "Cosine similarity: 0.656\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"vanilla floral perfume\"\n",
    "q_vec = model_faster.encode([query])[0].tolist()\n",
    "\n",
    "top_n = 5\n",
    "threshold = 0.5\n",
    "\n",
    "result = collection.query.near_vector(\n",
    "    near_vector=q_vec,\n",
    "    target_vector=\"desc_embedding\",\n",
    "    limit=top_n,\n",
    "    return_properties=[\"url\", \"description\"],\n",
    "    return_metadata=[\"distance\"]\n",
    ")\n",
    "\n",
    "filtered_results = []\n",
    "for obj in result.objects:\n",
    "    distance = obj.metadata.distance\n",
    "    if distance is not None:\n",
    "        similarity = 1 - distance\n",
    "        if similarity >= threshold:\n",
    "            filtered_results.append((obj, similarity))\n",
    "\n",
    "for obj, sim in filtered_results:\n",
    "    print(f\"URL: {obj.properties['url']}\")\n",
    "    print(f\"Description: {obj.properties['description']}\")\n",
    "    print(f\"Cosine similarity: {sim:.3f}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05681f85",
   "metadata": {},
   "source": [
    "–ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è API –∫–ª—é—á–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "dcd3d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENROUTER_KEY\"] = (\n",
    "    ...\n",
    ")\n",
    "OPENROUTER_KEY = os.environ[\"OPENROUTER_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d0469",
   "metadata": {},
   "source": [
    "- –ì–æ—Ç—É—î–º–æ –∑–∞–ø–∏—Ç –¥–æ API (–º–æ–¥–µ–ª—å claude-3.5-sonnet)\n",
    "- –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –∑–∞–ø–∏—Ç —ñ –æ—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å\n",
    "- –í–∏–≤–æ–¥–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8dc875ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–∏–≤—ñ—Ç! –Ø - Claude, —Ä–æ–∑–º–æ–≤–Ω–∏–π –®–Ü-–∞—Å–∏—Å—Ç–µ–Ω—Ç, —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –∫–æ–º–ø–∞–Ω—ñ—î—é Anthropic. –Ø –º–æ–∂—É –¥–æ–ø–æ–º–æ–≥—Ç–∏ –≤–∞–º –∑ —Ä—ñ–∑–Ω–∏–º–∏ –∑–∞–≤–¥–∞–Ω–Ω—è–º–∏ - –≤—ñ–¥ –Ω–∞–ø–∏—Å–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—ñ–≤ –¥–æ –∞–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö —Ç–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"–ü—Ä–∏–≤—ñ—Ç, —Ö—Ç–æ —Ç–∏?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=data)\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b441a82",
   "metadata": {},
   "source": [
    "### –ü–æ—à—É–∫—É —Ç–∞ —É—Ç–æ—á–Ω–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É\n",
    "- –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–ø–∏—Ç—É –Ω–∞ –∑–º—ñ—Å—Ç\n",
    "- –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –ø–æ—à—É–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cf843f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def check_user_query(query: str) -> str:\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "        \"max_tokens\": 200,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"–¢–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç, —è–∫–∏–π –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –º—ñ—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ–ø–∏—Å –∞—Ä–æ–º–∞—Ç–∏—á–Ω–∏—Ö –Ω–æ—Ç –ø–∞—Ä—Ñ—É–º—É \"\n",
    "                    \"(–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: –≤–∞–Ω—ñ–ª—å, —Ü–∏—Ç—Ä—É—Å, –º—É—Å–∫—É—Å, –¥–µ—Ä–µ–≤–Ω–∏–π, –∫–≤—ñ—Ç–∫–æ–≤–∏–π, —Ñ—Ä—É–∫—Ç–æ–≤–∏–π —Ç–æ—â–æ). \"\n",
    "                    \"–Ø–∫—â–æ —Ç–µ–∫—Å—Ç –º—ñ—Å—Ç–∏—Ç—å —Ö–æ—á–∞ –± –æ–¥–Ω—É —Ç–∞–∫—É –Ω–æ—Ç—É ‚Äî –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π –¢–Ü–õ–¨–ö–ò —Å–ª–æ–≤–æ–º 'ok'. \"\n",
    "                    \"–Ø–∫—â–æ –æ–ø–∏—Å –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∞—Ä–æ–º–∞—Ç–∏—á–Ω–∏—Ö –Ω–æ—Ç –∞–±–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ ‚Äî \"\n",
    "                    \"–∑–∞–¥–∞–π –∫–æ—Ä–æ—Ç–∫–µ —É—Ç–æ—á–Ω–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, –Ω–µ –±—ñ–ª—å—à–µ 15 —Å–ª—ñ–≤. \"\n",
    "                    \"–ù–µ –ø–æ—è—Å–Ω—é–π, –Ω–µ –∞–Ω–∞–ª—ñ–∑—É–π, –Ω–µ –ø–æ–≤—Ç–æ—Ä—é–π –≤—Ö—ñ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç.\"\n",
    "                ),\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=data,\n",
    "            timeout=15,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "    except (requests.exceptions.RequestException, KeyError) as e:\n",
    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–∏—Ç—É: {e}\")\n",
    "        return \"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∑–∞–ø–∏—Ç, —Å–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d1f10e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude: –Ø–∫—ñ —Å–∞–º–µ –∞—Ä–æ–º–∞—Ç–∏ –≤–∏ —à—É–∫–∞—î—Ç–µ - –≤–∞–Ω—ñ–ª—å–Ω—ñ, –∫–≤—ñ—Ç–∫–æ–≤—ñ, —Ñ—Ä—É–∫—Ç–æ–≤—ñ?\n"
     ]
    }
   ],
   "source": [
    "test_query = \"–ú–µ–Ω—ñ —Ö–æ—á–µ—Ç—å—Å—è —â–æ—Å—å —Å–æ–ª–æ–¥–∫–µ\"\n",
    "result = check_user_query(test_query)\n",
    "print(\"Claude:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5985174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_user_query(full_query: str, model):\n",
    "    vector = model.encode([full_query])[0].tolist()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c4e282c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_weaviate(vector, collection, k=5):\n",
    "    result = collection.query.near_vector(\n",
    "        near_vector=vector,\n",
    "        target_vector=\"desc_embedding\",\n",
    "        limit=k,\n",
    "        return_properties=[\"url\", \"description\"],\n",
    "    )\n",
    "    return result.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "40a8858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rerank_results(vector, results, model):\n",
    "    sims = []\n",
    "    for obj in results:\n",
    "        desc = obj.properties[\"description\"]\n",
    "        vec = model.encode([desc])[0].reshape(1, -1)\n",
    "        sim = cosine_similarity([vector], vec)[0][0]\n",
    "        sims.append((sim, obj))\n",
    "\n",
    "    sims.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [o for _, o in sims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "07c2841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(\n",
    "    query: str, results, model_name=\"anthropic/claude-3.5-sonnet\", top_k=5\n",
    "):\n",
    "\n",
    "    if not results:\n",
    "        return \"üòï –ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –°–ø—Ä–æ–±—É–π –æ–ø–∏—Å–∞—Ç–∏ –∞—Ä–æ–º–∞—Ç —ñ–Ω–∞–∫—à–µ.\"\n",
    "\n",
    "    context_docs = []\n",
    "    for obj in results[:top_k]:\n",
    "        url = obj.properties.get(\"url\", \"\")\n",
    "        desc = obj.properties.get(\"description\", \"\")\n",
    "        context_docs.append(f\"{url}\\n{desc}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "\n",
    "    rag_prompt = f\"\"\"\n",
    "–¢–∏ ‚Äî –∫–æ—Ä–∏—Å–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç, —è–∫–∏–π –¥–æ–ø–æ–º–∞–≥–∞—î –ø—ñ–¥—ñ–±—Ä–∞—Ç–∏ –∞—Ä–æ–º–∞—Ç –ø–∞—Ä—Ñ—É–º—ñ–≤. \n",
    "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –Ω–∞–≤–µ–¥–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —â–æ–± –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –Ω–∞ –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞. \n",
    "–û–±–æ–≤'—è–∑–∫–æ–≤–æ –¥–æ—Ç—Ä–∏–º—É–π—Å—è –ø—Ä–∞–≤–∏–ª:\n",
    "\n",
    "1. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n",
    "2. –ö–æ—Ä–æ—Ç–∫–æ –ø–æ—è—Å–Ω–∏, —è–∫—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –ø—ñ–¥—ñ–π—à–ª–∏ —Ç–∞ —á–æ–º—É.\n",
    "3. –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∞—Ä–æ–º–∞—Ç—É –≤–∫–∞–∂–∏ –ø—Ä—è–º–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –∞—Ä–æ–º–∞—Ç –Ω–∞ —Å–∞–π—Ç—ñ https://www.fragrantica.com (—è–∫—â–æ URL —î).\n",
    "4. –ù–µ –≤–∏–≥–∞–¥—É–π –∞—Ä–æ–º–∞—Ç–∏ —ñ –Ω–µ –¥–æ–¥–∞–≤–∞–π –Ω–µ–ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é.\n",
    "5. –ù–µ –ø–æ–≤—Ç–æ—Ä—é–π —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Ç—É —ñ –Ω–µ –ø–æ—è—Å–Ω—é–π –ø—Ä–æ—Ü–µ—Å.\n",
    "\n",
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç (URL + –æ–ø–∏—Å):\n",
    "{context}\n",
    "\n",
    "–ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"–¢–∏ –∫–æ—Ä–∏—Å–Ω–∏–π –∞—Ä–æ–º–∞—Ç–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç.\"},\n",
    "            {\"role\": \"user\", \"content\": rag_prompt},\n",
    "        ],\n",
    "        \"temperature\": 0.4,\n",
    "        \"max_tokens\": 300,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=data,\n",
    "            timeout=15,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        result = r.json()\n",
    "        llm_answer = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return f\"–í—ñ–¥–ø–æ–≤—ñ–¥—å:\\n{llm_answer}\"\n",
    "\n",
    "    except (requests.exceptions.RequestException, KeyError) as e:\n",
    "        print(f\"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–∏—Ç—É –¥–æ LLM: {e}\")\n",
    "        return \"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∑–∞–ø–∏—Ç, —Å–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "342628bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_user_message_kate(message: str, model, collection):\n",
    "\n",
    "    clarifying = check_user_query(message)\n",
    "    if clarifying.lower() != \"ok\":\n",
    "        return clarifying\n",
    "\n",
    "    user_vec = encode_user_query(message, model)\n",
    "    raw_results = search_in_weaviate(user_vec, collection, k=5)\n",
    "    ranked = rerank_results(user_vec, raw_results, model)\n",
    "    answer = generate_response(message, ranked)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# print(\n",
    "#     handle_user_message_kate(\n",
    "#         \"Generate something with vanilla and strawberry for me\",\n",
    "#         model_faster,\n",
    "#         collection,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5eb68c",
   "metadata": {},
   "source": [
    "- –û–±—Ä–æ–±–ª—è—î —Ç–µ–∫—Å—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (query), —è–∫–∏–π —Ç—Ä–µ–±–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –æ–ø–∏—Å—É –∞—Ä–æ–º–∞—Ç–∏—á–Ω–∏—Ö –Ω–æ—Ç.\n",
    "- –§–æ—Ä–º—É—î –∑–∞–ø–∏—Ç –¥–æ –º–æ–¥–µ–ª—ñ anthropic/claude-3.5-sonnet —á–µ—Ä–µ–∑ OpenRouter\n",
    "- –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –∑–∞–ø–∏—Ç –Ω–∞ —Å–µ—Ä–≤–µ—Ä —ñ —á–µ–∫–∞—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å (–Ω–µ –±—ñ–ª—å—à–µ 15 —Å–µ–∫—É–Ω–¥)\n",
    "- –û—Ç—Ä–∏–º—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ –º–æ–¥–µ–ª—ñ —É JSON-—Ñ–æ—Ä–º–∞—Ç—ñ.\n",
    "- –ü–æ–≤–µ—Ä—Ç–∞—î —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ ‚Äî 'ok', —è–∫—â–æ –æ–ø–∏—Å —î, –∞–±–æ —É—Ç–æ—á–Ω–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, —è–∫—â–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –±—Ä–∞–∫—É—î. –Ø–∫—â–æ —â–æ—Å—å –ø—ñ—à–ª–æ –Ω–µ —Ç–∞–∫ (–ø–æ–º–∏–ª–∫–∞ –º–µ—Ä–µ–∂—ñ –∞–±–æ API), —Ç–æ –ø–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d11569",
   "metadata": {},
   "source": [
    "### –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö —Ç–∞ –≤–∏—Ç—è–≥ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö –Ω–æ—Ç —ñ–∑ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "–¶–µ–π –±–ª–æ–∫ —á–∏—Ç–∞—î —Ñ–∞–π–ª fra_working.csv, –≤–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç–∏ –∑ –∫–æ–ª–æ–Ω–æ–∫ Top/Middle/Base/Main Accords,\n",
    "–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î —ó—Ö, –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –ø–æ–≤—Ç–æ—Ä—é–≤–∞–Ω—ñ –¥–≤–æ—Å–ª—ñ–≤–Ω—ñ —Ç–∞ –æ–¥–Ω–æ—Å–ª–æ–≤–Ω—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó,\n",
    "—ñ –±—É–¥—É—î –≥–ª–æ–±–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫ EXPLICIT_NOTES ‚Äî –Ω–∞–±—ñ—Ä —É—Å—ñ—Ö –Ω–æ—Ç, —è–∫—ñ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—Å—É—Ç–Ω—ñ —É –±–∞–∑—ñ.\n",
    "–°–∞–º–µ —Ü–µ–π —Å–ø–∏—Å–æ–∫ –¥–æ–∑–≤–æ–ª—è—î –±–æ—Ç—É –≤–∏–∑–Ω–∞—á–∏—Ç–∏, —á–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–∞–∑–≤–∞–≤ —Ä–µ–∞–ª—å–Ω—ñ –Ω–æ—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e4905",
   "metadata": {},
   "source": [
    "### –°–ª–æ–≤–Ω–∏–∫ –∞—Ä–æ–º–∞—Ç–∏—á–Ω–∏—Ö –ø—ñ–¥–∫–∞—Ç–µ–≥–æ—Ä—ñ–π (–ø–æ—Ç—Ä—ñ–±–Ω–∏–π –¥–ª—è —É—Ç–æ—á–Ω—é—é—á–∏—Ö –ø–∏—Ç–∞–Ω—å)\n",
    "–¶–µ–π –±–ª–æ–∫ —Å—Ç–≤–æ—Ä—é—î —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–µ –¥–µ—Ä–µ–≤–æ –∞—Ä–æ–º–∞—Ç–∏—á–Ω–∏—Ö –≥—Ä—É–ø,\n",
    "—è–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —É—Ç–æ—á–Ω—é–≤–∞–ª—å–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å,\n",
    "–∫–æ–ª–∏ –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ—á—ñ—Ç–∫–∏–π (—Ç–∏–ø—É: ‚Äú—Ö–æ—á—É —â–æ—Å—å —Å–æ–ª–æ–¥–∫–µ‚Äù –∞–±–æ ‚Äú—â–æ—Å—å —Å–≤—ñ–∂–µ‚Äù)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd96b77",
   "metadata": {},
   "source": [
    "### –ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Ç–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≥—Ä—É–ø –∞—Ä–æ–º–∞—Ç—ñ–≤\n",
    "–¶–µ–π –±–ª–æ–∫:\n",
    "- –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î —Ç–µ–∫—Å—Ç\n",
    "- –≤–∏–∑–Ω–∞—á–∞—î, —á–∏ –º—ñ—Å—Ç–∏—Ç—å –≤—ñ–Ω —Ä–µ–∞–ª—å–Ω—ñ –Ω–æ—Ç–∏\n",
    "- –≤–∏–∑–Ω–∞—á–∞—î, –¥–æ —è–∫–∏—Ö –≥—Ä—É–ø –∞—Ä–æ–º–∞—Ç—ñ–≤ –Ω–∞–ª–µ–∂–∏—Ç—å –∑–∞–ø–∏—Ç\n",
    "- –±—É–¥—É—î –ø—Ä–∞–≤–∏–ª—å–Ω—ñ —É—Ç–æ—á–Ω—é—é—á—ñ –ø–∏—Ç–∞–Ω–Ω—è, —è–∫—â–æ –∑–∞–ø–∏—Ç –Ω–µ—á—ñ—Ç–∫–∏–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26931b",
   "metadata": {},
   "source": [
    "### –°–∏—Å—Ç–µ–º–Ω–∏–π prompt –¥–ª—è LLM\n",
    "–¶–µ–π prompt –Ω–∞–≤—á–∞—î –º–æ–¥–µ–ª—å:\n",
    "- –∫–æ–ª–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ ‚Äúok‚Äù\n",
    "- –∫–æ–ª–∏ —Å—Ç–∞–≤–∏—Ç–∏ —É—Ç–æ—á–Ω–µ–Ω–Ω—è\n",
    "- —è–∫ —Ñ–æ—Ä–º—É–≤–∞—Ç–∏ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è\n",
    "- —è–∫—ñ —Å—Ç–∏–ª—ñ—Å—Ç–∏—á–Ω—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91024eaf",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü—ñ—è –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É —É –≤–∏–ø–∞–¥–∫—É –ø–æ—à—É–∫—É –ø–æ —Å—Ö–æ–∂–æ—Å—Ç—ñ –¥–æ –ø–∞—Ä—Ñ—É–º—É"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b666094",
   "metadata": {},
   "source": [
    "### check_user_query\n",
    "–¶–µ–π –±–ª–æ–∫ –æ—Ü—ñ–Ω—é—î –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –π –≤–∏—Ä—ñ—à—É—î:\n",
    "- –ß–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —É–∂–µ –≤–∫–∞–∑–∞–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –Ω–æ—Ç–∏ ‚Üí –ø–æ–≤–µ—Ä—Ç–∞—î \"ok\"\n",
    "- –ß–∏ —Ü–µ –µ–º–æ—Ü—ñ–π–Ω–∏–π –æ–ø–∏—Å ‚Üí —Ñ–æ—Ä–º—É—î —É—Ç–æ—á–Ω—é—é—á–µ –ø–∏—Ç–∞–Ω–Ω—è\n",
    "- –ß–∏ –∑–∞–ø–∏—Ç –∑–∞–Ω–∞–¥—Ç–æ –Ω–µ—á—ñ—Ç–∫–∏–π ‚Üí –Ω–∞–¥—Å–∏–ª–∞—î prompt —É Claude\n",
    "- –û–±—Ä–æ–±–ª—è—î –ø–æ–º–∏–ª–∫–∏ ‚Üí –¥–∞—î fallback –ø–∏—Ç–∞–Ω–Ω—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e9851",
   "metadata": {},
   "source": [
    "—è–∫—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –≤–≤—ñ–≤ –Ω–∞–∑–≤—É –ø–∞—Ä—Ñ—É–º—É —à—É–∫–∞—î–º–æ —á–∏ —î –≤–æ–Ω–∞ —É –Ω–∞—à—ñ–π –∫–æ–ª–µ–∫—Ü—ñ—ó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b7c3f",
   "metadata": {},
   "source": [
    "—è–∫—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —Ö–æ—á–µ —Å—Ö–æ–∂–∏–π –∞—Ä–æ–º–∞—Ç –Ω–∞ –∑–∞–¥–∞–Ω–∏–π, –≤–∏—Ç—è–≥—É—î–º–æ –æ–ø–∏—Å –∑–∞–¥–∞–Ω–æ–≥–æ –ø–∞—Ä—Ñ—É–º—É"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36386ea6",
   "metadata": {},
   "source": [
    "–ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î —Ç–µ–∫—Å—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–∞ –≤–µ–∫—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0d210",
   "metadata": {},
   "source": [
    "- –®—É–∫–∞—î–º–æ —É –∫–æ–ª–µ–∫—Ü—ñ—ó Weaviate –Ω–∞–π–±—ñ–ª—å—à —Å—Ö–æ–∂—ñ –≤–µ–∫—Ç–æ—Ä–∏ –∑–∞ –ø–æ–ª–µ–º desc_embedding –¥–æ \"–≤–µ–∫—Ç–æ—Ä—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞\"\n",
    "- –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Ç–æ–ø‚Äëk (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º 5)\n",
    "- –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Å–ø–∏—Å–æ–∫ –æ–±‚Äô—î–∫—Ç—ñ–≤ –∑ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—è–º–∏ url —ñ description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d95ea",
   "metadata": {},
   "source": [
    "- –ü—Ä–∏–π–º–∞—î –∑–Ω–∞–π–¥–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ Weaviate —ñ —ó—Ö–Ω—ñ –æ–ø–∏—Å–∏\n",
    "- –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î –∫–æ–∂–µ–Ω –æ–ø–∏—Å —É –≤–µ–∫—Ç–æ—Ä –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –º–æ–¥–µ–ª—ñ\n",
    "- –û–±—á–∏—Å–ª—é—î cosine similarity –º—ñ–∂ –≤–µ–∫—Ç–æ—Ä–æ–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —ñ –∫–æ–∂–Ω–∏–º –æ–ø–∏—Å–æ–º\n",
    "- –°–æ—Ä—Ç—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é –≤—ñ–¥ –Ω–∞–π–≤–∏—â–æ—ó –¥–æ –Ω–∞–π–Ω–∏–∂—á–æ—ó.\n",
    "- –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –æ–±‚Äô—î–∫—Ç—ñ–≤, –≤—ñ–¥ –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à–æ–≥–æ –¥–æ –Ω–∞–π–º–µ–Ω—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52a634",
   "metadata": {},
   "source": [
    "### –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd579d5",
   "metadata": {},
   "source": [
    "- –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –∑–∞–ø–∏—Ç—É\n",
    "- –§–æ—Ä–º—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç —ñ–∑ —Ç–æ–ø-K –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –∞—Ä–æ–º–∞—Ç—ñ–≤ (URL + –æ–ø–∏—Å)\n",
    "- –°—Ç–≤–æ—Ä—é—î —á—ñ—Ç–∫—É RAG-–ø—ñ–¥–∫–∞–∑–∫—É –¥–ª—è –º–æ–¥–µ–ª—ñ\n",
    "- –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –∑–∞–ø–∏—Ç –¥–æ OpenRouter / Claude\n",
    "- –û—Ç—Ä–∏–º—É—î —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É\n",
    "- –û–±—Ä–æ–±–ª—è—î –ø–æ–º–∏–ª–∫–∏, —è–∫—â–æ –∑–∞–ø–∏—Ç –Ω–µ –≤–¥–∞–≤—Å—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c6155",
   "metadata": {},
   "source": [
    "### –§—ñ–Ω–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f11f5",
   "metadata": {},
   "source": [
    "## –û–Ω–æ–≤–ª–µ–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç –∫–µ–π—Å—É –∑ –ø–æ—à—É–∫–æ–º –ø–æ —Å—Ö–æ–∂–æ—Å—Ç—ñ –¥–æ –ø–µ–≤–Ω–æ–≥–æ –ø–∞—Ä—Ñ—É–º—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b0485807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "EXTRACT_NAME_PROMPT = \"\"\"\n",
    "–¢–∏ ‚Äî –µ–∫—Å–ø–µ—Ä—Ç –∑ –ø–∞—Ä—Ñ—É–º–µ—Ä—ñ—ó.\n",
    "\n",
    "–ó–∞–≤–¥–∞–Ω–Ω—è:\n",
    "1. –í–∏—Ç—è–≥–Ω—É—Ç–∏ –∑ —Ç–µ–∫—Å—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –ù–ê–ó–í–£ —Ç–∞ –ë–†–ï–ù–î –ø–∞—Ä—Ñ—É–º—É, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ —î –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏.\n",
    "2. –Ø–∫—â–æ –Ω–∞–∑–≤–∞ –Ω–∞–ø–∏—Å–∞–Ω–∞ –ø—Ä–∏–±–ª–∏–∑–Ω–æ ‚Äî –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ —ó—ó.\n",
    "3. –Ø–∫—â–æ –Ω–∞–∑–≤–∏ –Ω–µ–º–∞—î –∑–æ–≤—Å—ñ–º –∞–±–æ –≤–æ–Ω–∞ –Ω–µ—á—ñ—Ç–∫–∞ ‚Äî –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ JSON –∑—ñ status=\"fail\" —ñ –∫–æ—Ä–æ—Ç–∫–∏–º —É—Ç–æ—á–Ω–µ–Ω–Ω—è–º.\n",
    "4. –í—ñ–¥–ø–æ–≤—ñ–¥—å —Å—Ç—Ä–æ–≥–æ —É JSON.\n",
    "\n",
    "–£—Å–ø—ñ—à–Ω–æ:\n",
    "{\n",
    "  \"status\": \"ok\",\n",
    "  \"brand\": \"Tom Ford\",\n",
    "  \"name\": \"Lost Cherry\"\n",
    "}\n",
    "\n",
    "–ü–æ—Ç—Ä—ñ–±–Ω–µ —É—Ç–æ—á–Ω–µ–Ω–Ω—è:\n",
    "{\n",
    "  \"status\": \"fail\",\n",
    "  \"error_sms\": \"–£—Ç–æ—á–Ω—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–∑–≤—É –∞—Ä–æ–º–∞—Ç—É.\"\n",
    "}\n",
    "\n",
    "–í–∞–∂–ª–∏–≤–æ:\n",
    "‚Ä¢ –ù–ï –≤–∏–≥–∞–¥—É–π –Ω–µ—ñ—Å–Ω—É—é—á–∏—Ö –∞—Ä–æ–º–∞—Ç—ñ–≤.\n",
    "‚Ä¢ –Ø–∫—â–æ –º–æ–∂–µ—à –∑–¥–æ–≥–∞–¥–∞—Ç–∏—Å—è, —â–æ –º–∞–≤ –Ω–∞ —É–≤–∞–∑—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á ‚Äî –≤–∏–ø—Ä–∞–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.\n",
    "‚Ä¢ –í—ñ–¥–ø–æ–≤—ñ–¥—å –¢–Ü–õ–¨–ö–ò JSON.\n",
    "\"\"\"\n",
    "\n",
    "def extract_perfume_name_AI_clean(user_text: str, OPENROUTER_KEY: str) -> dict:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 200,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": EXTRACT_NAME_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_text}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=data,\n",
    "            timeout=12\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        raw = r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        # –º–æ–∂–Ω–∞ –∑–∞–ª–æ–≥—É–≤–∞—Ç–∏, —è–∫—â–æ —â–æ—Å—å –ø—ñ–¥–µ –Ω–µ —Ç–∞–∫\n",
    "        # print(\"RAW NAME EXTRACTION:\", raw)\n",
    "        return json.loads(raw)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"NAME EXTRACTION ERROR:\", e)\n",
    "        return {\n",
    "            \"status\": \"fail\",\n",
    "            \"error_sms\": \"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –Ω–∞–∑–≤—É. –ù–∞–ø–∏—à—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, —Ç–æ—á–Ω—ñ—à–µ.\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1adb327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES_FROM_AI_PROMPT = \"\"\"\n",
    "–¢–∏ ‚Äî –ø–∞—Ä—Ñ—É–º–µ—Ä–Ω–∏–π –µ–∫—Å–ø–µ—Ä—Ç.\n",
    "\n",
    "–ó–∞–≤–¥–∞–Ω–Ω—è:\n",
    "1. –î–ª—è –∞—Ä–æ–º–∞—Ç—É {brand} {name} –ø–æ–≤–µ—Ä–Ω–∏ —Ç—ñ–ª—å–∫–∏:\n",
    "   - –≤–µ—Ä—Ö–Ω—ñ –Ω–æ—Ç–∏\n",
    "   - —Å–µ—Ä–µ–¥–Ω—ñ –Ω–æ—Ç–∏\n",
    "   - —Å—Ç–∞—Ç—å –∞—Ä–æ–º–∞—Ç—É (female / male / unisex)\n",
    "\n",
    "–ü–æ–≤–µ—Ä–Ω–∏ STRICT JSON:\n",
    "{\n",
    "  \"top\": [\"...\"],\n",
    "  \"middle\": [\"...\"],\n",
    "  \"gender\": \"female\" | \"male\" | \"unisex\"\n",
    "}\n",
    "\n",
    "–ù—ñ—è–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω—å.\n",
    "\"\"\"\n",
    "\n",
    "def get_notes_from_ai(brand, name, OPENROUTER_KEY):\n",
    "    prompt = NOTES_FROM_AI_PROMPT.format(brand=brand, name=name)\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                          headers=headers, json=data, timeout=15)\n",
    "        raw = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return json.loads(raw)\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "31d5d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gender_from_description(desc: str):\n",
    "    desc_low = desc.lower()\n",
    "\n",
    "    if \"for women\" in desc_low or \"women's\" in desc_low or \"female\" in desc_low:\n",
    "        return \"female\"\n",
    "\n",
    "    if \"for men\" in desc_low or \"men's\" in desc_low or \"male\" in desc_low:\n",
    "        return \"male\"\n",
    "\n",
    "    if \"unisex\" in desc_low:\n",
    "        return \"unisex\"\n",
    "\n",
    "    return \"unisex\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "224cdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perfume_in_db_or_AI(brand, name, model, collection, OPENROUTER_KEY):\n",
    "    query = f\"{brand} {name}\"\n",
    "    vec = model.encode([query])[0].tolist()\n",
    "\n",
    "    result = collection.query.near_vector(\n",
    "        near_vector=vec,\n",
    "        limit=1,\n",
    "        return_properties=[\"url\", \"description\"]\n",
    "    )\n",
    "\n",
    "    if result.objects:\n",
    "        obj = result.objects[0]\n",
    "        desc = obj.properties[\"description\"]\n",
    "\n",
    "        top = re.findall(r\"Top notes are ([^.]+)\", desc)\n",
    "        top = top[0].split(\", \") if top else []\n",
    "\n",
    "        middle = re.findall(r\"Middle notes are ([^.]+)\", desc)\n",
    "        middle = middle[0].split(\", \") if middle else []\n",
    "\n",
    "        gender = extract_gender_from_description(desc)\n",
    "\n",
    "        return {\n",
    "            \"top\": top,\n",
    "            \"middle\": middle,\n",
    "            \"gender\": gender,\n",
    "            \"source\": \"db\"\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        return get_notes_from_ai(brand, name, OPENROUTER_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9d2e480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_notes(top, middle, model):\n",
    "    combined = \", \".join(top + middle)\n",
    "    return model.encode([combined])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "13b7d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_gender(vector, gender, collection, k=20):\n",
    "\n",
    "    allowed = [\"unisex\"]\n",
    "    if gender == \"female\":\n",
    "        allowed += [\"female\"]\n",
    "    elif gender == \"male\":\n",
    "        allowed += [\"male\"]\n",
    "    else:\n",
    "        allowed = [\"male\", \"female\", \"unisex\"]\n",
    "\n",
    "    result = collection.query.near_vector(\n",
    "        near_vector=vector,\n",
    "        target_vector=\"desc_embedding\",\n",
    "        limit=k,\n",
    "        return_properties=[\"url\", \"description\"]\n",
    "    )\n",
    "    # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –ø–æ —Å—Ç–∞—Ç—ñ –∑ –æ–ø–∏—Å—É:\n",
    "    filtered = []\n",
    "    for o in result.objects:\n",
    "        desc = o.properties.get(\"description\", \"\")\n",
    "        gender_extracted = extract_gender_from_description(desc)\n",
    "\n",
    "        if gender_extracted in allowed:\n",
    "            filtered.append(o)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "842b44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def rerank_with_threshold(vector, candidates, model, threshold=0.39):\n",
    "    scored = []\n",
    "    for obj in candidates:\n",
    "        desc = obj.properties[\"description\"]\n",
    "        dvec = model.encode([desc])[0].reshape(1, -1)\n",
    "        sim = cosine_similarity([vector], dvec)[0][0]\n",
    "        if sim >= threshold:\n",
    "            scored.append((sim, obj))\n",
    "\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [o for _, o in scored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "914bdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_similarity_response(base_perfume_name, base_notes, results, gender_preference, model_name=\"anthropic/claude-3.5-sonnet\", top_k=5):\n",
    "\n",
    "    if not results:\n",
    "        return \"üòï –ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π—à–æ–≤ –ø–æ–¥—ñ–±–Ω–∏—Ö –∞—Ä–æ–º–∞—Ç—ñ–≤.\"\n",
    "\n",
    "    context_docs = []\n",
    "    for obj in results[:top_k]:\n",
    "        url = obj.properties.get(\"url\", \"\")\n",
    "        desc = obj.properties.get(\"description\", \"\")\n",
    "        context_docs.append(f\"{url}\\n{desc}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "\n",
    "    gender_text = {\n",
    "        \"male\": \"–¥–ª—è —á–æ–ª–æ–≤—ñ–∫—ñ–≤\",\n",
    "        \"female\": \"–¥–ª—è –∂—ñ–Ω–æ–∫\",\n",
    "        \"unisex\": \"—É–Ω—ñ—Å–µ–∫—Å\"\n",
    "    }.get(gender_preference, \"—É–Ω—ñ—Å–µ–∫—Å\")\n",
    "\n",
    "    rag_prompt = f\"\"\"\n",
    "–¢–∏ ‚Äî –ø–∞—Ä—Ñ—É–º–µ—Ä–Ω–∏–π –µ–∫—Å–ø–µ—Ä—Ç.\n",
    "\n",
    "–ë–∞–∑–æ–≤–∏–π –∞—Ä–æ–º–∞—Ç:\n",
    "{base_perfume_name}\n",
    "–û—Å–Ω–æ–≤–Ω—ñ –Ω–æ—Ç–∏:\n",
    "{base_notes}\n",
    "\n",
    "–°—Ç–∞—Ç—å –∞—Ä–æ–º–∞—Ç—É, —è–∫—É —à—É–∫–∞—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á: {gender_text}\n",
    "\n",
    "–û—Å—å —Å–ø–∏—Å–æ–∫ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —É –±–∞–∑—ñ –∞—Ä–æ–º–∞—Ç—ñ–≤:\n",
    "{context}\n",
    "\n",
    "–¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è:\n",
    "\n",
    "‚Ä¢ –û–±–µ—Ä–∏ 3‚Äì5 –∞—Ä–æ–º–∞—Ç—ñ–≤ –∑ –≤–∏—â–∏–º –ø–æ–∫–∞–∑–Ω–∏–∫–æ–º —Å—Ö–æ–∂–æ—Å—Ç—ñ(—Ç–æ–±—Ç–æ –≤ –ø–µ—Ä—à—ñ–π —á–∞—Å—Ç–∏–Ω—ñ)\n",
    "‚Ä¢ –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –Ω–∞–ø–∏—à–∏ –û–î–ò–ù –∞–±–∑–∞—Ü —Å—Ç—Ä–æ–≥–æ —É —Ñ–æ—Ä–º–∞—Ç—ñ:\n",
    "\n",
    "1. –ù–∞–∑–≤–∞ –∞—Ä–æ–º–∞—Ç—É —Ç–∞ –±—Ä–µ–Ω–¥\n",
    "URL\n",
    "1‚Äì2 —Ä–µ—á–µ–Ω–Ω—è –ø—Ä–æ—Å—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –ø—Ä–æ —Ç–µ, —á–æ–º—É –≤—ñ–Ω —Å—Ö–æ–∂–∏–π (—Å—Ç–∏–ª—å, —Ö–∞—Ä–∞–∫—Ç–µ—Ä, –Ω–∞—Å—Ç—Ä—ñ–π, –ø—Ä–æ—Ñ—ñ–ª—å).\n",
    "\n",
    "‚Ä¢ –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π bullet points.\n",
    "‚Ä¢ –ù–ï —Ä–æ–±–∏ —Ö—ñ–º—ñ—á–Ω–∏—Ö –∞–Ω–∞–ª—ñ–∑—ñ–≤.\n",
    "‚Ä¢ –ù–ï –ø–∏—à–∏ —Å–ø–∏—Å–∫—ñ–≤ –Ω–æ—Ç.\n",
    "‚Ä¢ –ù–ï –∑–≥–∞–¥—É–π –≤–µ—Ä—Ö–Ω—ñ/—Å–µ—Ä–µ–¥–Ω—ñ/–±–∞–∑–æ–≤—ñ –Ω–æ—Ç–∏.\n",
    "‚Ä¢ –ù–µ –ø–æ—è—Å–Ω—é–π –ø—Ä–æ—Ü–µ—Å.\n",
    "‚Ä¢ –ù–ï –¥–æ–¥–∞–≤–∞–π –∞—Ä–æ–º–∞—Ç—ñ–≤, —è–∫–∏—Ö –Ω–µ–º–∞—î –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ.\n",
    "‚Ä¢ –§–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –º–∞—î –±—É—Ç–∏ —ñ–¥–µ–Ω—Ç–∏—á–Ω–∏–π —É –í–°–Ü–• –∫–µ–π—Å–∞—Ö, –Ω–∞–≤—ñ—Ç—å –∫–æ–ª–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø—Ä–æ—Å–∏—Ç—å —ñ–Ω—à–∏–π –≥–µ–Ω–¥–µ—Ä.\n",
    "‚Ä¢ –ù–µ –≤–∏–≥–∞–¥—É–π –Ω—ñ—á–æ–≥–æ –ø–æ–∑–∞ –ø–µ—Ä–µ–¥–∞–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º.\n",
    "\n",
    "–ü–∏—à–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n",
    "\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"–¢–∏ –∫–æ—Ä–∏—Å–Ω–∏–π –∞—Ä–æ–º–∞—Ç–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç.\"},\n",
    "            {\"role\": \"user\", \"content\": rag_prompt},\n",
    "        ],\n",
    "        \"temperature\": 0.15,\n",
    "        \"max_tokens\": 600\n",
    "    }\n",
    "\n",
    "    r = requests.post(\n",
    "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=data,\n",
    "        timeout=15\n",
    "    )\n",
    "\n",
    "    return \"–í—ñ–¥–ø–æ–≤—ñ–¥—å:\\n\" + r.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "041c1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_user_message_similarity(user_text, model, collection, OPENROUTER_KEY):\n",
    "\n",
    "    name_data = extract_perfume_name_AI_clean(user_text, OPENROUTER_KEY)\n",
    "\n",
    "    if name_data[\"status\"] == \"fail\":\n",
    "        return name_data[\"error_sms\"]\n",
    "\n",
    "    brand = name_data[\"brand\"]\n",
    "    name = name_data[\"name\"]\n",
    "\n",
    "    perfume_data = find_perfume_in_db_or_AI(\n",
    "        brand, name, model, collection, OPENROUTER_KEY\n",
    "    )\n",
    "\n",
    "    if not perfume_data:\n",
    "        return \"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –Ω–æ—Ç–∏ –∞—Ä–æ–º–∞—Ç—É. –°–ø—Ä–æ–±—É–π—Ç–µ —ñ–Ω—à—É –Ω–∞–∑–≤—É.\"\n",
    "\n",
    "    top = perfume_data[\"top\"]\n",
    "    middle = perfume_data[\"middle\"]\n",
    "    gender = perfume_data[\"gender\"]\n",
    "\n",
    "    vector = encode_notes(top, middle, model)\n",
    "\n",
    "    candidates = search_by_gender(vector, gender, collection)\n",
    "\n",
    "    ranked = rerank_with_threshold(vector, candidates, model)\n",
    "    \n",
    "    notes_text = \", \".join(top + middle)\n",
    "\n",
    "    return generate_similarity_response(base_perfume_name=name, base_notes=notes_text, results=ranked, gender_preference=gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "19aa18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# print(\n",
    "#     handle_user_message_similarity(\n",
    "#         \"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ Tom Ford Lost Cherry\",\n",
    "#         model_faster,\n",
    "#         collection,\n",
    "#         ...,\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "00f3d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(handle_user_message_similarity(\"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ Tom Ford Lost Cherry –∞–ª–µ –¥–ª—è —á–æ–ª–æ–≤—ñ–∫—ñ–≤\", model_faster, collection, OPENROUTER_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d26421a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(handle_user_message_similarity(\"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ Tom Ford Lost Cherry –∞–ª–µ –∑ —à–æ–∫–æ–ª–∞–¥–æ–º\", model_faster, collection, OPENROUTER_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a8fb71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(handle_user_message_similarity(\"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ –ª–æ—Å—Ç —á–µ—Ä—ñ\", model_faster, collection, OPENROUTER_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "954b61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(handle_user_message_similarity(\"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ \", model_faster, collection, OPENROUTER_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1823e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(handle_user_message_similarity(\"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ω–∞ –ª—Å—Ç —á–µ—ñ\", model_faster, collection, OPENROUTER_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "64655400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(handle_user_message_similarity(\"–Ø —Ö–æ—á—É —â–æ—Å—å —Å—Ö–æ–∂–µ –Ωa tom ford\", model_faster, collection, OPENROUTER_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d75eab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def init_db():\n",
    "    conn = sqlite3.connect(\"user_data.db\")\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS user_profile (\n",
    "            user_id INTEGER PRIMARY KEY,\n",
    "            gender TEXT,\n",
    "            liked_perfumes TEXT,\n",
    "            liked_notes TEXT\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ba778aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user(user_id, gender):\n",
    "    conn = sqlite3.connect(\"user_data.db\")\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\n",
    "        \"\"\"\n",
    "        INSERT OR REPLACE INTO user_profile (user_id, gender, liked_perfumes, liked_notes)\n",
    "        VALUES (?, ?, '', '')\n",
    "        \"\"\",\n",
    "        (user_id, gender),\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def clear_user_data(user_id):\n",
    "    conn = sqlite3.connect(\"user_data.db\")\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\n",
    "        \"\"\"\n",
    "        UPDATE user_profile\n",
    "        SET liked_perfumes = '', liked_notes = ''\n",
    "        WHERE user_id = ?\n",
    "        \"\"\",\n",
    "        (user_id,),\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def get_user_profile(user_id):\n",
    "    conn = sqlite3.connect(\"user_data.db\")\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\n",
    "        \"SELECT liked_perfumes, liked_notes FROM user_profile WHERE user_id = ?\",\n",
    "        (user_id,),\n",
    "    )\n",
    "    row = c.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if not row:\n",
    "        return None\n",
    "\n",
    "    perfumes, notes = row\n",
    "\n",
    "    return {\n",
    "        \"liked_perfumes\": perfumes.split(\", \") if perfumes else [],\n",
    "        \"liked_notes\": notes.split(\", \") if notes else [],\n",
    "    }\n",
    "\n",
    "\n",
    "def add_liked_perfume(user_id, perfume):\n",
    "    profile = get_user_profile(user_id)\n",
    "    if not profile:\n",
    "        return\n",
    "\n",
    "    perfumes = set(profile[\"liked_perfumes\"])\n",
    "    perfumes.add(perfume)\n",
    "\n",
    "    perfumes_str = \", \".join(perfumes)\n",
    "\n",
    "    conn = sqlite3.connect(\"user_data.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\n",
    "        \"UPDATE user_profile SET liked_perfumes = ? WHERE user_id = ?\",\n",
    "        (perfumes_str, user_id),\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def add_liked_note(user_id, note):\n",
    "    profile = get_user_profile(user_id)\n",
    "    if not profile:\n",
    "        return\n",
    "\n",
    "    notes = set(profile[\"liked_notes\"])\n",
    "    notes.add(note)\n",
    "\n",
    "    notes_str = \", \".join(notes)\n",
    "\n",
    "    conn = sqlite3.connect(\"user_data.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\n",
    "        \"UPDATE user_profile SET liked_notes = ? WHERE user_id = ?\",\n",
    "        (notes_str, user_id),\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "def add_notes_list_to_db(user_id, notes_list):\n",
    "    for note in notes_list:\n",
    "        add_liked_note(user_id, note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8872388",
   "metadata": {},
   "source": [
    "### Telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2f9329f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES_FROM_AI_PROMPT = \"\"\"\n",
    "–¢–∏ ‚Äî –ø–∞—Ä—Ñ—É–º–µ—Ä–Ω–∏–π –µ–∫—Å–ø–µ—Ä—Ç.\n",
    "\n",
    "–ó–∞–≤–¥–∞–Ω–Ω—è:\n",
    "1. –î–ª—è –∞—Ä–æ–º–∞—Ç—É {brand} {name} –ø–æ–≤–µ—Ä–Ω–∏ —Ç—ñ–ª—å–∫–∏:\n",
    "   - –≤–µ—Ä—Ö–Ω—ñ –Ω–æ—Ç–∏\n",
    "   - —Å–µ—Ä–µ–¥–Ω—ñ –Ω–æ—Ç–∏\n",
    "   - —Å—Ç–∞—Ç—å –∞—Ä–æ–º–∞—Ç—É (female / male / unisex)\n",
    "\n",
    "–ü–æ–≤–µ—Ä–Ω–∏ STRICT JSON:\n",
    "{{\n",
    "  \"top\": [\"...\"],\n",
    "  \"middle\": [\"...\"],\n",
    "  \"gender\": \"female\" | \"male\" | \"unisex\"\n",
    "}}\n",
    "\n",
    "–ù—ñ—è–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω—å.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_all_notes(names, brands, OPENROUTER_KEY):\n",
    "    all_notes = []\n",
    "\n",
    "    for name, brand in zip(names, brands):\n",
    "        prompt = NOTES_FROM_AI_PROMPT.format(brand=brand, name=name)\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "            \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            r = requests.post(\n",
    "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=data,\n",
    "                timeout=15,\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            raw = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            notes = json.loads(raw)\n",
    "            all_notes.extend(notes.get(\"top\", []))\n",
    "            all_notes.extend(notes.get(\"middle\", []))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–æ—Ç–æ–∫ –¥–ª—è {brand} {name}: {e}\")\n",
    "            continue\n",
    "    return list(set(all_notes))\n",
    "\n",
    "\n",
    "OPENROUTER_KEY = (\n",
    "    ...\n",
    ")\n",
    "\n",
    "names = [\"Fitnessence\", \"Frangipane e Cocco\", \"XVII Baroque Russian Coriander\"]\n",
    "brands = [\"Matriarch\", \"I Profumi di Firenze\", \"Clive Christian\"]\n",
    "\n",
    "# all_notes_list = get_all_notes(names, brands, OPENROUTER_KEY)\n",
    "\n",
    "# print(\"–í—Å—ñ –Ω–æ—Ç–∫–∏:\", all_notes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "deae4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiogram.types import ReplyKeyboardMarkup, KeyboardButton\n",
    "from aiogram.fsm.context import FSMContext\n",
    "from aiogram import types\n",
    "from aiogram.filters import Command\n",
    "import asyncio\n",
    "from aiogram import Bot, Dispatcher, Router, types\n",
    "from aiogram.filters import Command\n",
    "from aiogram.fsm.context import FSMContext\n",
    "from aiogram.fsm.state import State, StatesGroup\n",
    "from aiogram.fsm.storage.memory import MemoryStorage\n",
    "from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup\n",
    "\n",
    "TOKEN = TOKEN\n",
    "\n",
    "class Form(StatesGroup):\n",
    "    waiting_for_gender = State()\n",
    "    waiting_for_description = State()\n",
    "    waiting_for_name = State()\n",
    "\n",
    "router = Router()\n",
    "\n",
    "def gender_kb():\n",
    "    return ReplyKeyboardMarkup(\n",
    "        keyboard=[[KeyboardButton(text=\"–ñ—ñ–Ω–æ—á–∞\"), KeyboardButton(text=\"–ß–æ–ª–æ–≤—ñ—á–∞\")]],\n",
    "        resize_keyboard=True,\n",
    "        one_time_keyboard=True,\n",
    "    )\n",
    "\n",
    "@router.message(Command(\"start\"))\n",
    "async def cmd_start(message: types.Message, state: FSMContext):\n",
    "    user_id = message.from_user.id\n",
    "    user = get_user_profile(user_id)\n",
    "    print(user)\n",
    "    if user:\n",
    "        await message.answer(\n",
    "            \"–ü—Ä–∏–≤—ñ—Ç! üëã –†–∞–¥–∏–π –±–∞—á–∏—Ç–∏ —Ç–µ–±–µ –∑–Ω–æ–≤—É!\", reply_markup=main_menu_kb()\n",
    "        )\n",
    "        return\n",
    "    await message.answer(\n",
    "        \"–ü—Ä–∏–≤—ñ—Ç! üëã\\n–û–±–µ—Ä–∏, –±—É–¥—å –ª–∞—Å–∫–∞, —Å–≤–æ—é —Å—Ç–∞—Ç—å:\",\n",
    "        reply_markup=gender_kb(),\n",
    "    )\n",
    "    await state.set_state(Form.waiting_for_gender)\n",
    "\n",
    "\n",
    "def main_menu_kb():\n",
    "    return InlineKeyboardMarkup(\n",
    "        inline_keyboard=[\n",
    "            [\n",
    "                InlineKeyboardButton(\n",
    "                    text=\"üå∑ –ü–æ—à—É–∫ –∑–∞ –Ω–∞–∑–≤–æ—é –ø–∞—Ä—Ñ—É–º—É\",\n",
    "                    callback_data=\"search_by_description\",\n",
    "                )\n",
    "            ],\n",
    "            [\n",
    "                InlineKeyboardButton(\n",
    "                    text=\"‚ú® –ü—ñ–¥–±—ñ—Ä –∞—Ä–æ–º–∞—Ç—É –∑–∞ –æ–ø–∏—Å–æ–º\",\n",
    "                    callback_data=\"search_by_name\",\n",
    "                )\n",
    "            ],\n",
    "            [\n",
    "                InlineKeyboardButton(\n",
    "                    text=\"‚ú® –ü—ñ–¥–±—ñ—Ä –∞—Ä–æ–º–∞—Ç—É –∑–∞ –≤–ª–∞—Å–Ω–∏–º–∏ –≤–ø–æ–¥–æ–±–∞–Ω–Ω—è–º–∏\",\n",
    "                    callback_data=\"search_by_user\",\n",
    "                )\n",
    "            ],\n",
    "            [InlineKeyboardButton(text=\"–ü—Ä–æ –±–æ—Ç–∞\", callback_data=\"about\")],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "@router.message(Form.waiting_for_gender)\n",
    "async def process_gender(message: types.Message, state: FSMContext):\n",
    "    gender = message.text.strip()\n",
    "\n",
    "    if gender not in [\"–ñ—ñ–Ω–æ—á–∞\", \"–ß–æ–ª–æ–≤—ñ—á–∞\"]:\n",
    "        await message.answer(\n",
    "            \"–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä–∏ –æ–¥–∏–Ω –∑ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤:\", reply_markup=gender_kb()\n",
    "        )\n",
    "        return\n",
    "    user_id = message.from_user.id\n",
    "    add_user(user_id, gender)\n",
    "\n",
    "    await state.update_data(gender=gender)\n",
    "    await message.answer(f\"–î—è–∫—É—é! –û–±—Ä–∞–Ω–∞ —Å—Ç–∞—Ç—å: {gender}.\", reply_markup=main_menu_kb())\n",
    "    await state.clear()\n",
    "\n",
    "\n",
    "@router.message(Command(\"help\"))\n",
    "async def cmd_help(message: types.Message):\n",
    "    await message.answer(\n",
    "        \"–ö–æ–º–∞–Ω–¥–∏:\\n\"\n",
    "        \"/start ‚Äî –ø–æ—á–∞—Ç–∏\\n\"\n",
    "        \"/help ‚Äî –¥–æ–ø–æ–º–æ–≥–∞\\n\\n\"\n",
    "        \"–ù–∞–¥—ñ—à–ª–∏ –±—É–¥—å-—è–∫–∏–π —Ç–µ–∫—Å—Ç ‚Äî —è –≤—ñ–¥–ø–æ–≤—ñ–º –µ—Ö–æ.\"\n",
    "    )\n",
    "\n",
    "\n",
    "@router.callback_query(lambda c: c.data == \"about\")\n",
    "async def cb_about(callback: types.CallbackQuery):\n",
    "    await callback.message.answer(\n",
    "        \"‚ÑπÔ∏è –¶–µ–π –±–æ—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–∞ aiogram 3.3.0.\\n–í—ñ–Ω –ø–æ–∫–∞–∑—É—î –ø—Ä–∏–∫–ª–∞–¥ –∫–Ω–æ–ø–æ–∫ —ñ FSM.\"\n",
    "    )\n",
    "    await callback.answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d29cb",
   "metadata": {},
   "source": [
    "# –ü—ñ–¥–±—ñ—Ä –∑–∞ –Ω–∞–∑–≤–æ—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "16704646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def feedback_kb():\n",
    "    return InlineKeyboardMarkup(\n",
    "        inline_keyboard=[\n",
    "            [\n",
    "                InlineKeyboardButton(text=\"üåü –°–ø–æ–¥–æ–±–∞–ª–æ—Å—å\", callback_data=\"liked\"),\n",
    "                InlineKeyboardButton(\n",
    "                    text=\"‚ùå –ù–µ —Å–ø–æ–¥–æ–±–∞–ª–æ—Å—å\", callback_data=\"disliked\"\n",
    "                ),\n",
    "            ],\n",
    "            [InlineKeyboardButton(text=\"üè† –ì–æ–ª–æ–≤–Ω–µ –º–µ–Ω—é\", callback_data=\"main_menu\")],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "OPENROUTER_KEY = (\n",
    "    ...\n",
    ")\n",
    "def get_all_notes(names, brands, OPENROUTER_KEY):\n",
    "    all_notes = []\n",
    "\n",
    "    for name, brand in zip(names, brands):\n",
    "        prompt = NOTES_FROM_AI_PROMPT.format(brand=brand, name=name)\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "            \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            r = requests.post(\n",
    "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=data,\n",
    "                timeout=15,\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            raw = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            notes = json.loads(raw)\n",
    "\n",
    "            all_notes.extend(notes.get(\"top\", []))\n",
    "            all_notes.extend(notes.get(\"middle\", []))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–æ—Ç–æ–∫ –¥–ª—è {brand} {name}: {e}\")\n",
    "            continue\n",
    "    return list(set(all_notes))\n",
    "\n",
    "\n",
    "def extract_perfume_names(text: str):\n",
    "    pattern = pattern = r\"(?:[:.\\n]\\s*)(.+?)\\s+–≤—ñ–¥\\b\"\n",
    "    names = re.findall(pattern, text)\n",
    "    return names\n",
    "\n",
    "\n",
    "def extract_perfume_brands(text: str):\n",
    "    pattern = r\"–≤—ñ–¥\\s+(.+?)\\s+https\"\n",
    "    brands = re.findall(pattern, text)\n",
    "    return brands\n",
    "\n",
    "@router.message(Form.waiting_for_description)\n",
    "async def process_description(message: types.Message, state: FSMContext):\n",
    "    full_prompt = message.text.strip()\n",
    "    print(full_prompt)\n",
    "    recs = handle_user_message_similarity(\n",
    "        full_prompt, model_faster, collection, OPENROUTER_KEY\n",
    "    )\n",
    "    perfume_names = extract_perfume_names(recs)\n",
    "    perfume_brands = extract_perfume_brands(recs)\n",
    "    all_notes_list = get_all_notes(perfume_names, perfume_brands, OPENROUTER_KEY)\n",
    "    add_notes_list_to_db(message.from_user.id, all_notes_list)\n",
    "\n",
    "    print(all_notes_list)\n",
    "    await state.update_data(last_recommendations=perfume_names)\n",
    "    await message.answer(recs)\n",
    "    await message.answer(\"–û–±–µ—Ä—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞:\", reply_markup=feedback_kb())\n",
    "    await state.set_state(Form.waiting_for_description)\n",
    "    # await message.answer(\"–û–±–µ—Ä—ñ—Ç—å –Ω–∞—Å—Ç—É–ø–Ω—É –¥—ñ—é:\", reply_markup=main_menu_kb())\n",
    "\n",
    "    # await state.clear()\n",
    "\n",
    "\n",
    "@router.callback_query(lambda c: c.data in [\"liked\", \"disliked\", \"main_menu\"])\n",
    "async def cb_feedback(callback: types.CallbackQuery, state: FSMContext):\n",
    "    data = await state.get_data()\n",
    "    perfume_names = data.get(\"last_recommendations\", [])\n",
    "    user_id = callback.from_user.id\n",
    "\n",
    "    if callback.data == \"liked\":\n",
    "        for perfume in perfume_names:\n",
    "            add_liked_perfume(user_id, perfume)\n",
    "        await callback.message.answer(\"‚úÖ –î–æ–¥–∞–Ω–æ —É –≤–∞—à—ñ —É–ª—é–±–ª–µ–Ω—ñ –∞—Ä–æ–º–∞—Ç–∏!\")\n",
    "\n",
    "    elif callback.data == \"disliked\":\n",
    "        await callback.message.answer(\"‚ùå –î–æ–±—Ä–µ, –Ω–µ –¥–æ–¥–∞—î–º–æ –Ω—ñ—á–æ–≥–æ.\")\n",
    "\n",
    "    elif callback.data == \"main_menu\":\n",
    "        await callback.message.answer(\n",
    "            \"üè† –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –≤ –≥–æ–ª–æ–≤–Ω–µ –º–µ–Ω—é\", reply_markup=main_menu_kb()\n",
    "        )\n",
    "\n",
    "    await callback.answer()\n",
    "    await state.clear()\n",
    "\n",
    "\n",
    "@router.callback_query(lambda c: c.data == \"search_by_description\")\n",
    "async def cb_search_description(callback: types.CallbackQuery, state: FSMContext):\n",
    "    await callback.message.answer(\"–í–≤–µ–¥–∏ –æ–ø–∏—Å –±–∞–∂–∞–Ω–æ–≥–æ –∞—Ä–æ–º–∞—Ç—É:\")\n",
    "    await state.set_state(Form.waiting_for_description)\n",
    "    await callback.answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa5391",
   "metadata": {},
   "source": [
    "# –ü—ñ–¥–±—ñ—Ä –∑–∞ –≤–ø–æ–¥–æ–±–∞–Ω–Ω—è–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d6633f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "@router.callback_query(lambda c: c.data == \"search_by_user\")\n",
    "async def cb_search_by_user(callback: types.CallbackQuery, state: FSMContext):\n",
    "    user_id = callback.from_user.id\n",
    "\n",
    "    user_data = get_user_profile(user_id)\n",
    "    liked_notes = user_data.get(\"liked_notes\", []) if user_data else []\n",
    "\n",
    "    if not liked_notes:\n",
    "        await callback.message.answer(\n",
    "            \"‚ùó –£ –≤–∞—Å —â–µ –Ω–µ–º–∞—î —É–ª—é–±–ª–µ–Ω–∏—Ö –Ω–æ—Ç–æ–∫. –°–ø–µ—Ä—à—É –æ–±–µ—Ä—ñ—Ç—å –∞—Ä–æ–º–∞—Ç–∏, —â–æ–± –º–∏ –º–æ–≥–ª–∏ –ø—ñ–¥–±–∏—Ä–∞—Ç–∏ —Å—Ö–æ–∂—ñ.\"\n",
    "        )\n",
    "        await callback.message.answer(\n",
    "            \"–û–±–µ—Ä—ñ—Ç—å –Ω–∞—Å—Ç—É–ø–Ω—É –¥—ñ—é:\", reply_markup=main_menu_kb()\n",
    "        )\n",
    "        await callback.answer()\n",
    "        return\n",
    "\n",
    "    notes_prompt = f\"–ü—ñ–¥–±–µ—Ä–∏ –ø–∞—Ä—Ñ—É–º–∏ —è–∫—ñ –º—ñ—Å—Ç—è—Ç—å —Ç–∞–∫—ñ –Ω–æ—Ç–∫–∏: {', '.join(liked_notes)}. –£ —Å–≤–æ—ó–π –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–µ –≤–∫–∞–∑—É–π –Ω–æ—Ç–∏, —è–∫—ñ –≤—ñ–¥—Å—É—Ç–Ω—ñ –≤ –ø–∞—Ä—Ñ—É–º–∞—Ö, —è–∫—ñ —Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—à\"\n",
    "\n",
    "    recommended_perfumes = handle_user_message_kate(\n",
    "        message=notes_prompt,\n",
    "        model=model_faster,\n",
    "        collection=collection,\n",
    "    )\n",
    "\n",
    "    await callback.message.answer(\n",
    "        f\"üå∑ –û—Å—å –∞—Ä–æ–º–∞—Ç–∏, —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤–∞—à–∏—Ö —É–ª—é–±–ª–µ–Ω–∏—Ö –Ω–æ—Ç–æ–∫:\\n{recommended_perfumes}\"\n",
    "    )\n",
    "\n",
    "    await callback.message.answer(\n",
    "        \"–û–±–µ—Ä—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞:\",\n",
    "        reply_markup=feedback_kb(),\n",
    "    )\n",
    "\n",
    "    recommended_list = extract_perfume_names(recommended_perfumes)\n",
    "    await state.update_data(last_recommendations=recommended_list)\n",
    "    await state.set_state(Form.waiting_for_description)\n",
    "    await callback.answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd538c",
   "metadata": {},
   "source": [
    "# –ü—ñ–¥–±—ñ—Ä –∑–∞ –Ω–æ—Ç–∫–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e97fa86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@router.message(Form.waiting_for_name)\n",
    "async def process_name(message: types.Message, state: FSMContext):\n",
    "    name = message.text.strip()\n",
    "    if not name:\n",
    "        await message.answer(\"‚ùó –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥–∏ –Ω–∞–∑–≤—É –ø–∞—Ä—Ñ—É–º—É —â–µ —Ä–∞–∑.\")\n",
    "        return\n",
    "\n",
    "    answer = handle_user_message_kate(\n",
    "        message=name,\n",
    "        model=model_faster,\n",
    "        collection=collection,\n",
    "    )\n",
    "\n",
    "    await message.answer(f\"üå∑ –û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ {name}:\\n\\n{answer}\")\n",
    "    await state.clear()\n",
    "\n",
    "\n",
    "@router.callback_query(lambda c: c.data == \"search_by_name\")\n",
    "async def cb_search_name(callback: types.CallbackQuery, state: FSMContext):\n",
    "    await callback.message.answer(\"–í–≤–µ–¥–∏ –Ω–∞–∑–≤—É –ø–∞—Ä—Ñ—É–º—É:\")\n",
    "    await state.set_state(Form.waiting_for_name)\n",
    "    await callback.answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e03f7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–∏–π —ñ –ø—Ä–∞—Ü—é—î!\n",
      "{'liked_perfumes': ['Frangipane e Cocco', 'Fitnessence', 'Cherry Lush', 'Cherry Lust', 'Cherry', 'XVII Baroque Russian Coriander', 'Amarena Cherry'], 'liked_notes': ['–≤–∞–Ω—ñ–ª—å', '—à–æ–∫–æ–ª–∞–¥', '–∂–∞—Å–º–∏–Ω', '–∞–º–±—Ä–∞']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received SIGINT signal\n"
     ]
    }
   ],
   "source": [
    "# @router.message(Form.waiting_for_description)\n",
    "# async def process_description(message: types.Message, state: FSMContext):\n",
    "#     description = message.text.strip()\n",
    "#     data = await state.get_data()\n",
    "#     base_prompt = data.get(\"base_prompt\", \"\")\n",
    "#     previous_description = data.get(\"previous_description\", \"\")\n",
    "#     if not base_prompt:\n",
    "#     base_prompt = description\n",
    "#     await state.update_data(base_prompt=base_prompt)\n",
    "\n",
    "# recs = handle_user_message_similarity(\n",
    "#     description,\n",
    "#     model_faster,\n",
    "#     collection,\n",
    "#     \"\",\n",
    "# )\n",
    "# print(recs)\n",
    "# print(\"9\")\n",
    "# if isinstance(recs, dict):\n",
    "#     print(\"7\")\n",
    "#     if recs.get(\"status\") == \"fail\":\n",
    "#         print(\"–ø–æ–º–∏–ª–∫–∞\")\n",
    "#         await state.update_data(previous_description=description)\n",
    "#         await message.answer(result.get(\"error_sms\", \"–°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.\"))\n",
    "#         return\n",
    "# print(\"8\")\n",
    "# print(recs)\n",
    "# while \"—É—Ç–æ—á–Ω—ñ—Ç—å\" in recs.lower() or \"–≤–∫–∞–∂—ñ—Ç—å\" in recs.lower() or \"–Ω–µ –≤–¥–∞–ª–æ—Å—è\" in recs.lower():\n",
    "#     await state.update_data(previous_description=description)\n",
    "#     await message.answer(\n",
    "#         \"üîÑ –ú–æ–∂–ª–∏–≤–æ, —É—Ç–æ—á–Ω—ñ—Ç—å –≤–∞—à –æ–ø–∏—Å –∞—Ä–æ–º–∞—Ç—É —â–µ —Ä–∞–∑, –±—É–¥—å –ª–∞—Å–∫–∞.\"\n",
    "#     )\n",
    "#     return\n",
    "# await message.answer(recs)\n",
    "# await message.answer(\"–û–±–µ—Ä—ñ—Ç—å –Ω–∞—Å—Ç—É–ø–Ω—É –¥—ñ—é:\", reply_markup=main_menu_kb())\n",
    "# await state.clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@router.message()\n",
    "async def echo(message: types.Message):\n",
    "    if message.text and not message.text.startswith(\"/\"):\n",
    "        await message.answer(f\"–ï—Ö–æ: {message.text}\")\n",
    "    else:\n",
    "        await message.answer(\"–ù–µ–≤—ñ–¥–æ–º–∞ –∫–æ–º–∞–Ω–¥–∞. –°–ø—Ä–æ–±—É–π /help\")\n",
    "\n",
    "@router.callback_query(lambda c: c.data == \"search_by_name_with_notes\")\n",
    "async def cb_search_name_with_notes(callback: types.CallbackQuery):\n",
    "    await callback.message.answer(\n",
    "        \"–í–≤–µ–¥–∏ –Ω–∞–∑–≤—É –ø–∞—Ä—Ñ—É–º—É, –∞ –ø–æ—Ç—ñ–º –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –Ω–æ—Ç–∫–∏, —è–∫—ñ —Ö–æ—á–µ—à –¥–æ–¥–∞—Ç–∏ —á–∏ –≤–∏–∫–ª—é—á–∏—Ç–∏:\"\n",
    "    )\n",
    "    await callback.answer()\n",
    "\n",
    "async def main():\n",
    "    bot = Bot(token=...)\n",
    "    dp = Dispatcher(storage=MemoryStorage())\n",
    "    dp.include_router(router)\n",
    "    print(\"‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–∏–π —ñ –ø—Ä–∞—Ü—é—î!\")\n",
    "    await dp.start_polling(bot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å—ñ –Ω–æ—Ç–∫–∏: ['rose', 'frangipani', 'almond', 'coriander', 'bergamot', 'lemon', 'ylang-ylang', 'vanilla', 'jasmine', 'coconut', 'mandarin orange']\n"
     ]
    }
   ],
   "source": [
    "# def get_all_notes(names, brands, OPENROUTER_KEY):\n",
    "#     all_notes = []\n",
    "\n",
    "#     for name, brand in zip(names, brands):\n",
    "#         prompt = NOTES_FROM_AI_PROMPT.format(brand=brand, name=name)\n",
    "\n",
    "#         headers = {\n",
    "#             \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "#             \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "#         }\n",
    "\n",
    "#         data = {\n",
    "#             \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "#             \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#             \"temperature\": 0.1,\n",
    "#         }\n",
    "\n",
    "#         try:\n",
    "#             r = requests.post(\n",
    "#                 \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "#                 headers=headers,\n",
    "#                 json=data,\n",
    "#                 timeout=15,\n",
    "#             )\n",
    "#             r.raise_for_status()\n",
    "#             raw = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "#             notes = json.loads(raw)\n",
    "\n",
    "#             all_notes.extend(notes.get(\"top\", []))\n",
    "#             all_notes.extend(notes.get(\"middle\", []))\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–æ—Ç–æ–∫ –¥–ª—è {brand} {name}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     return list(set(all_notes))\n",
    "# OPENROUTER_KEY = ...\n",
    "\n",
    "# names = [\"Fitnessence\", \"Frangipane e Cocco\", \"XVII Baroque Russian Coriander\"]\n",
    "# brands = [\"Matriarch\", \"I Profumi di Firenze\", \"Clive Christian\"]\n",
    "\n",
    "# all_notes_list = get_all_notes(names, brands, OPENROUTER_KEY)\n",
    "\n",
    "# print(\"–í—Å—ñ –Ω–æ—Ç–∫–∏:\", all_notes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "79ca4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "\n",
    "# def update_liked_notes(user_id, notes_list):\n",
    "#     notes_str = \", \".join(notes_list)\n",
    "#     conn = sqlite3.connect(\"user_data.db\")\n",
    "#     c = conn.cursor()\n",
    "\n",
    "#     c.execute(\n",
    "#         \"UPDATE user_profile SET liked_notes = ? WHERE user_id = ?\",\n",
    "#         (notes_str, user_id),\n",
    "#     )\n",
    "\n",
    "#     conn.commit()\n",
    "#     conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "34bc0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = 717090644\n",
    "# new_notes = [\n",
    "#     \"–≤–∞–Ω—ñ–ª—å\",\n",
    "#     \"—à–æ–∫–æ–ª–∞–¥\",\n",
    "#     \"–∂–∞—Å–º–∏–Ω\",\n",
    "#     \"–∞–º–±—Ä–∞\",\n",
    "# ]\n",
    "\n",
    "# update_liked_notes(user_id, new_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
